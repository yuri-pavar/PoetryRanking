
### Автор
- Павар Юрий Александрович

# 1. Задача
Есть данные chitalnya.ru :
- Текст стихотворения
- Жанр
- Количество просмотров
- Оценка

Необходимо создать ранжировщик, оценивающий входные стихотворения

# 2. Данные и их особенности

### 2.1 Тексты
Если произвести самое просто разделение на слова, то во всей выборке 95% наблюдений имеет <= 165 слов.

Особенности:
- Стихотворения - это не обычный текст
- В поэзии часто используются метафоры, аллюзии, символизм и другие литературные приемы, которые обычно высоко оценивают люди и что может быть сложной задачей для модели
- Подчеркивать поэзию могут нестандартные или своеобразные пунктуация, слог, обороты и т д, что важно сохранить. **Стандартная предобработка текста (лемматизация, стемминг, удаление стоп-слов и пунктуации) в случае поэзии скорее не применима**
- Одним из важных качеств является ритм, который определяется как рифмой, так и структурой (переносы строк). Исходя из этого, кажется хорошим решением **указать модели переносы строк отдельным токеном**
- Т к стихотворения написаны обычными пользователями (хотя вроде бы есть модерация и самомодерация сообщества), **в данных могут быть различные ошибки** 


### 2.2 Жанры
В общем наборе данных 35 уникальных жанров, причем около 80% всех данных приходится на 3 жанра: лирика (около 50%), юмор, песни. 

Особенности:
- Разные жанры люди скорее всего **оценивают по-разному**
- В жанре “песни” в некоторых примерах **помимо текстов присутствуют музыка, сама песня (голос + музыка), видео**. Судя по комментариям многие оценивают не только текст, а все это в совокупности или даже только песню

### 2.3 Рейтинг
В общем наборе данных рейтинг - это дискретные значения от 0 до 1145, причем около 56% наблюдений это оценка 0.

Неизвестно по какому принципу строится рейтинг. Четкого алгоритма его вычисления на сайте не предоставляется. Из чего он может строится:
- Количество отзывов (есть на странице)
- Количество сообщений (есть на странице)
- Количество просмотров (есть на странице)
- Рейтинг самого автора
- Количество Подписчиков автора
- Количество рекомендаций автора
- Награды автора

Особенности:
- Т к сайт все-таки с любительской поэзией, **рейтинг может не отражать реальную литературную ценность произведения** (высокий рейтинг не значит хорошее качество и наоборот)
- Хороший рейтинг может быть **накручен**
- Стихотворение могло быть выложено совсем перед датой сбора данных и **могло не успеть набрать своих оценок**


# 3. Работа
### 3.1 Задача и метрика
##### 3.1.1 Варианты
Для задач анализа текстов хорошо подходят модели архитектуры BERT. Исходя из особенностей данных, в т.ч. что более 50% наблюдений с рейтингом 0, кажется, что есть 2 подхода к решению задачи:
1. Регрессия 
2. Бинарная классификация на 2 класса (рейтинг 0 и рейтинг >0) + регрессия на положительном классе для боле точного определения рейтинга

##### 3.1.2 Плюсы и минусы подходов
**Подход 1 (Регрессия)**

Плюсы:
- 1 модель проще реализовать и поддерживать
- Из-за 2 уровней моделей могу накапливаться ошибки, такая модель этого лишена

Минусы:
- Сама модель может быть сложной/"большой"
- Может переобучиться под класс с рейтингом 0 
- Меньшая точность на классе рейтинг >0

**Подход 2 (Классификация + Регрессия)**

Плюсы:
- Упрощение задачи, каждая модель проще/"меньше"
- Лучший учет различий в данных для разных классов

Минусы:
- Сложность настройки и вычислений для 2 моделей
- Из-за 2 уровней моделей могу накапливаться ошибки

##### 3.1.3 Итог
Для начала предлагается следующий пайплайн:
- модель - **бинарный классификатор на основе BERT** на 2 класса: рейтинг 0 и рейтинг >0
- для задачи ранжирования наиболее разумной метрикой кажется **ROC-AUC**
- оценить, насколько хорошо может решаться такая подзадача

### 3.2 Проба пера
Первым делом было сделано:
- EDA
- Предобработка данных, в т.ч. добавление нового токена для обозначения переносов строк **[NEWLINE]** (что будет использоваться всегда в дальнейшем)
- Бейзлайн на tf-idf 
- Классификатор на основе **DeepPavlov/rubert-base-cased** (сразу стало понятно, что слишком тяжелая для обучения на доступных мне данных)
- Классификатор на основе **cointegrated/rubert-tiny2** (более легкая модель, будет использоваться всегда в дальнейшем)

Результаты:

| Model         | ROC-AUC | Accuracy |
|---------------|---------|----------|
| tf-idf/logreg | 0.6518  | 0.6201   |
| t+g+v/3epochs | 0.637   | 0.6068   |

t - тексты, g - жанры, v- просмотры

Выводы:
- На одну эпоху уходило ~20 мин, что довольно долго
- Со второй же эпохи модель сильно переобучалась, поэтому результаты ожидаемо низкие

### 3.3 Новые признаки

В поисках информации нашел такие замечательные ресурсы:
1. https://github.com/polinadumbledore/poem_quality_evaluation/tree/main
2. https://huggingface.co/numblilbug/rubert-cased-poem-evalutation
3. https://github.com/MashaPo/russtress/tree/master
4. https://github.com/dbklim/StressRNN
5. https://github.com/versotym/rhymetagger/blob/master/tagger.py#L809
6. https://pypi.org/project/rusyll/

##### 3.3.1 Рифма [источник 5]
Получение признака:
- разметка строк стихотворения на рифмующиеся (наример, если выход [1, 2, 1, 2], то рифмуются 1,3 и 2,4 строки)
- работает достаточно хорошо, но все-таки некоторые более сложные рифмы не размечаются (-1 вв этом случае)
- для подачи в модель нужно их привести к 1 размеру - паддим нулями до макс длины 20 (75 перцентиль)
- работает долго, 10% train за 45 мин

##### 3.3.2 Смысловая наполненность, эмоциональность, корректность грамматики [источник 1]
Получение признака:
- получение предсказаний  на основе модели **numblilbug/rubert-cased-poem-evalutation** от авторов 
- модель на основе DeepPavlov/rubert-base-cased обучена на 1800 стихотрениях и размечена вручную на эти 3 класса
- все 3 прихнака бинарные

##### 3.3.3 Ритм (оценка) [источник 1]
Получение признака:
- получаем для каждой строки стихотворения ее разложение на слоги
- считаем длину каждой такой строки
- считаем количество уникальных длин таких разложений
- делим на общее количество строк
- инвертируем (1 - значение), т к исходное значение "чем меньше, тем лучше"
- более подробно прочитать об этом можно в источнике

##### 3.3.4 Ритм (схема) модификация [источник 1]
Получение признака:
- получаем для каждой строки стихотворения ее разложение на ударные и безударные слоги
- далее моя модификация
- вместо получения разложения для всей строки сразу, получим такое разложение для каждого слова с более чем 1 слогами (например, для строки [[1, 0], [0, 0, 1], ...])
- далее кодируем каждое слово по формуле ```результат = кол-во слогов + позиция ударного слога (1)/кол-во слогов``` (например, [3.0, 3.0, 3.66, 3.0, 2.5, ...])
- для подачи в модель нужно их привести к 1 размеру - паддим нулями до макс длины 60 (75 перцентиль)

##### 3.3.5 Жанр
Получение признака:
- признак был закодирован с помощью OneHotEncoding

##### 3.3.6 Просмотры
Получение признака:
- признак был масштабировн с помощью StandardScaler

### 3.4 Эксперименты и улучшения
Для ускорения выводов все эксперименты производились на подвыборке исходных данных. Размер - 17000, разделена на тест и обучение в соответствии с исходными данными - 20/80 

Некоторые результаты экспериментов:

| params                                     | ROC-AUC | Accuracy |
|--------------------------------------------|---------|----------|
| t+g+v/10 epochs/frozen/250tok/l_x2(128)    | 0.6991  | 0.6541   |
| all-rhyme/10epochs/frozen/250tok/l_x2(128) | 0.6869  | 0.6432   |
| all/10epochs/frozen/250tok/l_x2(128)       | 0.6855  | 0.6367   |
| t+g+v/10epochs/250tok/frozen               | 0.667   | 0.62     |
| t+g+v+r_e/10epochs/frozen/250tok           | 0.6629  | 0.6173   |
| t+g+v/10epochs/344tok/frozen               | 0.6621  | 0.6123   |
| t+g+v/10epochs/210tok/frozen               | 0.659   | 0.6152   |
| t+g+v+m+g+e/10epochs/frozen/250tok         | 0.6568  | 0.6123   |
| t+g+v+m+g+e+r_e/10epochs/frozen/250tok     | 0.654   | 0.6097   |
| all/10epochs/frozen/250tok                 | 0.6433  | 0.6091   |
| t+g+v+ry/10epochs/frozen/250tok            | 0.6418  | 0.612    |
| tf-idf/logreg                              | 0.602   | 0.5882   |
| t+g+v+m+g+e/4epochs/250tok                 | 0.59    | 0.5732   |
| t+g+v/5epochs/344tok                       | 0.5681  | 0.5558   |

t - тексты, g - жанры, v - просмотры

m - смысл, g - грамматика, e - эмоции

r_e - оценка ритма, r_s - ритм-схема, ry/rhyme - рифма

all - все признаки = t+g+v+m+g+e+r_e+r_s+ry

frozen - заморозка весов BERT, Ntok - max_len токенайзера, l_x2(128) - доп скрытый слой 


Выводы:
- проблема переобучения была решена заморозкой весов BERT
- экспериментально подобрана лучшая max_len токенайзера = 250 (75 перцентиль)
- новые признаки не дают прироста качества, возможно, стоит лучше поработать с ними
- добавление дополнительного скрытого слоя улучшило качество

### 3.5 Модель
Обучаем итоговую модель на всей исходной выборке и с лучшими параметрами, полученными в ходе экспериментов:
- вся исходная выборка
- модель - cointegrated/rubert-tiny2
- признаки: текст, жанр, просмотры
- max_len токенайзера = 185 (75 перцентиль)
- замораживаем веса BERT
- добавляем дополнительный скрытый слой
- обучаем 5 эпох (~ 1.5 часа)

Результаты:

| params                                | ROC-AUC | Accuracy |
|---------------------------------------|---------|----------|
| t+g+v/5epochs/frozen/185tok/l_x2(128) | 0.7311  | 0.6801   |
| tf-idf/logreg                         | 0.6518  | 0.6201   |

Выводы:
- Получилось заметно, но не намного повысить качество


# 4. Санити-чек

На продолжение работы над задачей, к сожалению, не осталось времени. 

Выводы по проделанной работе:
- классификация на 2 класса оказалась не такой легкой задачей как предполагалось в начале
- точно стоит рассмотреть подход1 с использованием 1 модели регрессии
- удалось получить несколько новых признаков, которые кажутся перспективными
- проведено достаточно большое количество экспериментов с различными параметрами
- **для задачи ранжирования** можно использовать выходы модели как степень уверенности модели в качестве произведения


# 5. Future work

В качестве будущей работы:
- рефакторинг кода
- попробовать новые архитектуры
- подбор гиперпараметров
- работа с новыми признаками. Как уже упоминалось, признаки кажутся перспективными, и, возможно, стоит более глубоко поработать над ними
- вероятно, стоит отказаться от модели классификации и сосредоточиться на полноценной модели регрессии
- использовать более "тяжелую" модель



